{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnhom3ds317\u001b[0m (\u001b[33mnhomcs331-beeditor\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is redundant as it is now the default behavior.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Read the WandB API key from the environment variable\n",
    "api_key = os.getenv(\"WANDB_API_KEY_2\")\n",
    "if api_key:\n",
    "    wandb.login(key=api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in environment. Please set it to your WandB API key.\")\n",
    "wandb.require(\"core\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # on notebook\n",
    "# import wandb\n",
    "# api_key  = \"your_api_key_here\"\n",
    "# wandb.login(key=api_key)\n",
    "# wandb.require(\"core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'program': 'train.py', 'name': 'model_sweep_updated_para', 'method': 'grid', 'metric': {'name': 'test_accuracy', 'goal': 'maximize'}, 'parameters': {'model': {'values': ['convnext', 'efficientnet', 'mobilenet', 'resnet', 'vit']}, 'dataset': {'value': 'hutech-dataset:latest'}, 'freeze': {'values': [False]}, 'pretrained': {'values': [True]}, 'resize': {'values': [224]}, 'horizontal_flip': {'values': [0.5]}, 'vertical_flip': {'values': [0.5]}, 'random_rotation': {'values': [90]}, 'random_affine': {'values': [0.2]}, 'random_perspective': {'values': [0.2]}, 'auto_aug': {'values': [1]}, 'num_classes': {'value': 4}, 'lr': {'value': '1e-5'}, 'num_epochs': {'value': 150}, 'batch_size': {'value': 4}, 'optimizer': {'value': 'adamw'}, 'scheduler': {'value': 'step'}, 'es_patience': {'value': 10}, 'weight_decay': {'value': 0.00025}, 'momentum': {'value': 0.9}}, 'command': ['${env}', 'python', '${program}']}\n",
      "Create sweep with ID: owl7xnxg\n",
      "Sweep URL: https://wandb.ai/nhomcs331-beeditor/hutech_mushroom/sweeps/owl7xnxg\n",
      "Sweep ID: owl7xnxg\n"
     ]
    }
   ],
   "source": [
    "# sweep_config = {\n",
    "#     'program': 'train.py',\n",
    "#     'method': 'random',  # Can be 'grid', 'random', or 'bayes'\n",
    "#     'metric': {\n",
    "#         'name': 'val_loss',  # The metric to optimize\n",
    "#         'goal': 'minimize'  # The optimization goal of the metric\n",
    "#     },\n",
    "#     'parameters': {\n",
    "#         'lr': {\n",
    "#             'distribution': 'uniform',\n",
    "#             'min': 1e-6,\n",
    "#             'max': 1e-2\n",
    "#         },\n",
    "#         'num_epochs': {\n",
    "#             'values': [10, 20, 30]\n",
    "#         },\n",
    "#         'batch_size': {\n",
    "#             'values': [16, 32, 64]\n",
    "#         },\n",
    "#         'optimizer': {\n",
    "#             'values': ['adam', 'sgd', 'adamw']\n",
    "#         },\n",
    "#         # You can add more hyperparameters as needed.\n",
    "#     }\n",
    "# }\n",
    "\n",
    "import wandb\n",
    "from utils.helper import load_config\n",
    "config_path = \"../config/sweep_model.yaml\"\n",
    "\n",
    "PROJECT = 'hutech_mushroom'\n",
    "with open(config_path, 'r') as f:\n",
    "    sweep_config = load_config(config_path)\n",
    "print(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=PROJECT)\n",
    "print(f\"Sweep ID: {sweep_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 ways to activate agent for sweeping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep ID: owl7xnxg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlj36e3c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tauto_aug: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: hutech-dataset:latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tes_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thorizontal_flip: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: convnext\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpretrained: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_affine: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_perspective: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_rotation: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tresize: 224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvertical_flip: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(model='alexnet', config=None, wandb=1, project='hutech_mushroom', dataset='hutech-dataset:latest')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: nhom3ds317 (nhomcs331-beeditor) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Ignoring project 'hutech_mushroom' when running a sweep.\n",
      "wandb: creating run\n",
      "wandb: Tracking run with wandb version 0.19.8\n",
      "wandb: Run data is saved locally in /mnt/c/Users/beeha/VSCode/Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/wandb/run-20250513_160812-jlj36e3c\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run stilted-sweep-1\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/nhomcs331-beeditor/hutech_mushroom\n",
      "wandb: üßπ View sweep at https://wandb.ai/nhomcs331-beeditor/hutech_mushroom/sweeps/owl7xnxg\n",
      "wandb: üöÄ View run at https://wandb.ai/nhomcs331-beeditor/hutech_mushroom/runs/jlj36e3c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE config! {'auto_aug': 1, 'batch_size': 4, 'dataset': 'hutech-dataset:latest', 'es_patience': 10, 'freeze': False, 'horizontal_flip': 0.5, 'lr': 1e-05, 'model': 'convnext', 'momentum': 0.9, 'num_classes': 4, 'num_epochs': 150, 'optimizer': 'adamw', 'pretrained': True, 'random_affine': 0.2, 'random_perspective': 0.2, 'random_rotation': 90, 'resize': 224, 'scheduler': 'step', 'vertical_flip': 0.5, 'weight_decay': 0.00025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1276 of 1276 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auto_aug': 1, 'batch_size': 4, 'dataset': 'hutech-dataset:latest', 'es_patience': 10, 'freeze': False, 'horizontal_flip': 0.5, 'lr': 1e-05, 'model': 'convnext', 'momentum': 0.9, 'num_classes': 4, 'num_epochs': 150, 'optimizer': 'adamw', 'pretrained': True, 'random_affine': 0.2, 'random_perspective': 0.2, 'random_rotation': 90, 'resize': 224, 'scheduler': 'step', 'vertical_flip': 0.5, 'weight_decay': 0.00025}\n",
      "Not using class weights here!!!!\n",
      "Class weights: None\n",
      "Training model...\n",
      "Device: cuda\n",
      "Number of epochs: 150\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 1e-05\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 0.00025\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Scheduler: <torch.optim.lr_scheduler.SequentialLR object at 0x7fbfdc09ea90>\n",
      "Total parameters: 49457764\n",
      "Trainable parameters: 49457764\n",
      "Batch size: 4\n",
      "Early stopping: 10\n",
      "Dataset: 588 training samples, 252 validation samples\n",
      "Model will be saved at ../weights/best-convnext-2025-05-13-16-08-25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:29<00:00,  4.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 51.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 1 with val loss 1.4569\n",
      "[Epoch 1/150] Train Loss: 1.4385 Val Loss: 1.4569 Train Acc: 0.2517 Val Acc: 0.2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:31<00:00,  4.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 2 with val loss 1.4510\n",
      "[Epoch 2/150] Train Loss: 1.4391 Val Loss: 1.4510 Train Acc: 0.2483 Val Acc: 0.2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:31<00:00,  4.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:06<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 3 with val loss 1.4464\n",
      "[Epoch 3/150] Train Loss: 1.4414 Val Loss: 1.4464 Train Acc: 0.2449 Val Acc: 0.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:31<00:00,  4.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 49.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 4 with val loss 1.4409\n",
      "[Epoch 4/150] Train Loss: 1.4485 Val Loss: 1.4409 Train Acc: 0.2296 Val Acc: 0.2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:32<00:00,  4.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 53.16it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/150] Train Loss: 1.4238 Val Loss: 1.4414 Train Acc: 0.2364 Val Acc: 0.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 9/147 [00:02<00:31,  4.37it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:33<00:00,  4.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 50.63it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/150] Train Loss: 1.4381 Val Loss: 1.4463 Train Acc: 0.2296 Val Acc: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:34<00:00,  4.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 47.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 7 with val loss 1.4226\n",
      "[Epoch 7/150] Train Loss: 1.4413 Val Loss: 1.4226 Train Acc: 0.2245 Val Acc: 0.2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:35<00:00,  4.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 49.61it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/150] Train Loss: 1.4399 Val Loss: 1.4235 Train Acc: 0.2398 Val Acc: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:34<00:00,  4.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 47.87it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/150] Train Loss: 1.4197 Val Loss: 1.4416 Train Acc: 0.2738 Val Acc: 0.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:34<00:00,  4.21it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 53.22it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/150] Train Loss: 1.4295 Val Loss: 1.4277 Train Acc: 0.2466 Val Acc: 0.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:34<00:00,  4.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 52.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 11 with val loss 1.4093\n",
      "[Epoch 11/150] Train Loss: 1.4285 Val Loss: 1.4093 Train Acc: 0.2432 Val Acc: 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:34<00:00,  4.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 51.65it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/150] Train Loss: 1.4161 Val Loss: 1.4259 Train Acc: 0.2789 Val Acc: 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:36<00:00,  4.06it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:05<00:00, 48.10it/s]\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/150] Train Loss: 1.4068 Val Loss: 1.4157 Train Acc: 0.2415 Val Acc: 0.2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [00:35<00:00,  4.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:04<00:00, 50.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 14 with val loss 1.3854\n",
      "[Epoch 14/150] Train Loss: 1.3978 Val Loss: 1.3854 Train Acc: 0.2874 Val Acc: 0.2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 63/147 [00:15<00:19,  4.23it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n",
      "message_loop has been closed\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
      "    return self._sock_client.read_server_response(timeout=1)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 235, in read_server_response\n",
      "    data = self._read_packet_bytes(timeout=timeout)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 220, in _read_packet_bytes\n",
      "    raise SockClientClosedError\n",
      "wandb.sdk.lib.sock_client.SockClientClosedError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 56, in message_loop\n",
      "    msg = self._read_message()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
      "    raise MessageRouterClosedError from e\n",
      "wandb.sdk.interface.router.MessageRouterClosedError\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 63/147 [00:15<00:20,  4.04it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/beeha/VSCode/Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 246, in <module>\n",
      "    trainer()\n",
      "  File \"/mnt/c/Users/beeha/VSCode/Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 180, in trainer\n",
      "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
      "  File \"/mnt/c/Users/beeha/VSCode/Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 46, in train_one_epoch\n",
      "    running_loss += loss.item() * images.size(0)\n",
      "KeyboardInterrupt\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "wandb.agent(sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 56, in _try_connect_to_existing_service\n",
      "    client.connect(token.port)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 102, in connect\n",
      "    s.connect((\"localhost\", port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/bin/wandb\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1161, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1082, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1697, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1443, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 788, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 1669, in agent\n",
      "    api = _get_cling_api()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 132, in _get_cling_api\n",
      "    wandb.setup(settings=wandb.Settings(x_cli_only_mode=True))\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 382, in setup\n",
      "    return _setup(settings=settings)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 321, in _setup\n",
      "    _singleton.ensure_service()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 264, in ensure_service\n",
      "    self._connection = service_connection.connect_to_service(self._settings)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 37, in connect_to_service\n",
      "    conn = _try_connect_to_existing_service()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 59, in _try_connect_to_existing_service\n",
      "    raise WandbServiceConnectionError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceConnectionError: Failed to connect to internal service.\n"
     ]
    }
   ],
   "source": [
    "# !wandb agent --count 20 {sweep_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
