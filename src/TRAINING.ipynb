{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(model='alexnet', config='../config/exp.yaml', project='hutech_mushroom', dataset='hutech-dataset:latest')\n",
      "HERE config! {'project': 'hutech_mushroom', 'dataset': 'hutech-dataset:latest', 'model': 'regnet', 'freeze': False, 'resize': 224, 'random_crop': 224, 'horizontal_flip': 0.5, 'vertical_flip': 0.5, 'random_rotation': 90, 'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.2, 'normalize': 1, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'random_erasing': 0.2, 'scheduler': 'cosine', 'es_patience': 10, 'num_classes': 4, 'lr': '1e-5', 'num_epochs': 30, 'batch_size': 4, 'optimizer': 'adam', 'weight_decay': 0.00025, 'momentum': 0.9}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeehappy2554\u001b[0m (\u001b[33mbeehappy2554-bosch-global\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/c/Users/beeha/VSCode/! - Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/wandb/run-20250330_183557-7k7nxx9l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretty-grass-281\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/beehappy2554-bosch-global/hutech_mushroom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/beehappy2554-bosch-global/hutech_mushroom/runs/7k7nxx9l\u001b[0m\n",
      "here config!!! {'project': 'hutech_mushroom', 'dataset': 'hutech-dataset:latest', 'model': 'regnet', 'freeze': False, 'resize': 224, 'random_crop': 224, 'horizontal_flip': 0.5, 'vertical_flip': 0.5, 'random_rotation': 90, 'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.2, 'normalize': 1, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'random_erasing': 0.2, 'scheduler': 'cosine', 'es_patience': 10, 'num_classes': 4, 'lr': '1e-5', 'num_epochs': 30, 'batch_size': 4, 'optimizer': 'adam', 'weight_decay': 0.00025, 'momentum': 0.9}\n",
      "HERE config! {'project': 'hutech_mushroom', 'dataset': 'hutech-dataset:latest', 'model': 'regnet', 'freeze': False, 'resize': 224, 'random_crop': 224, 'horizontal_flip': 0.5, 'vertical_flip': 0.5, 'random_rotation': 90, 'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.2, 'normalize': 1, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'random_erasing': 0.2, 'scheduler': 'cosine', 'es_patience': 10, 'num_classes': 4, 'lr': '1e-5', 'num_epochs': 30, 'batch_size': 4, 'optimizer': 'adam', 'weight_decay': 0.00025, 'momentum': 0.9}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1205 of 1205 files downloaded.  \n",
      "{'project': 'hutech_mushroom', 'dataset': 'hutech-dataset:latest', 'model': 'regnet', 'freeze': False, 'resize': 224, 'random_crop': 224, 'horizontal_flip': 0.5, 'vertical_flip': 0.5, 'random_rotation': 90, 'brightness': 0.2, 'contrast': 0.2, 'saturation': 0.2, 'normalize': 1, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'random_erasing': 0.2, 'scheduler': 'cosine', 'es_patience': 10, 'num_classes': 4, 'lr': '1e-5', 'num_epochs': 30, 'batch_size': 4, 'optimizer': 'adam', 'weight_decay': 0.00025, 'momentum': 0.9}\n",
      "Training model...\n",
      "Device: cuda\n",
      "Number of epochs: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 1e-05\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.00025\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f299fcfd430>\n",
      "Total parameters: 3904908\n",
      "Batch size: 4\n",
      "Early stopping: 10\n",
      "Dataset: 720 training samples, 120 validation samples\n",
      "Model will be saved at ../models/best-regnet-2025-03-30-18:36:26.pt\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.92it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 66.83it/s]\n",
      "/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Saving model at epoch 1 with val loss 1.3303\n",
      "[Epoch 1/30] Train Loss: 1.3890 Val Loss: 1.3303 Train Acc: 0.2875 Val Acc: 0.3833\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:10<00:00, 16.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 64.96it/s]\n",
      "Saving model at epoch 2 with val loss 1.2759\n",
      "[Epoch 2/30] Train Loss: 1.3166 Val Loss: 1.2759 Train Acc: 0.3944 Val Acc: 0.4417\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 16.16it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 61.07it/s]\n",
      "Saving model at epoch 3 with val loss 1.2166\n",
      "[Epoch 3/30] Train Loss: 1.2418 Val Loss: 1.2166 Train Acc: 0.4722 Val Acc: 0.5250\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.05it/s]\n",
      "  4%|‚ñà‚ñä                                         | 5/120 [00:00<00:02, 47.29it/s]"
     ]
    }
   ],
   "source": [
    "!python train.py --config ../config/exp.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
