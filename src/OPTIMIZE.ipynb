{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeehappy2554\u001b[0m (\u001b[33mbeehappy2554-bosch-global\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('core')` is redundant as it is now the default behavior.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Read the WandB API key from the environment variable\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "if api_key:\n",
    "    wandb.login(key=api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in environment. Please set it to your WandB API key.\")\n",
    "wandb.require(\"core\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'program': 'train.py', 'name': 'model_sweep', 'method': 'grid', 'metric': {'name': 'test_accuracy', 'goal': 'maximize'}, 'parameters': {'model': {'values': ['alexnet', 'convnext', 'densenet', 'efficientnet', 'mobilenet', 'resnet', 'vit', 'inception', 'negnet', 'resnext', 'shufflenet']}, 'dataset': {'value': 'hutech-dataset:latest'}, 'resize': {'values': [224]}, 'horizontal_flip': {'values': [0.5]}, 'vertical_flip': {'values': [0.5]}, 'random_rotation': {'values': [90]}, 'contrast': {'values': [0.2]}, 'saturation': {'values': [0.2]}, 'num_classes': {'value': 4}, 'lr': {'value': '1e-5'}, 'num_epochs': {'value': 30}, 'batch_size': {'value': 4}, 'optimizer': {'value': 'adam'}, 'scheduler': {'value': 'reduce_lr_on_plateau'}, 'es_patience': {'value': 10}, 'weight_decay': {'value': 0.0001}, 'momentum': {'value': 0.9}}, 'command': ['${env}', 'python', '${program}']}\n",
      "Create sweep with ID: v1g5ljm5\n",
      "Sweep URL: https://wandb.ai/beehappy2554-bosch-global/hutech_mushroom/sweeps/v1g5ljm5\n",
      "Sweep ID: v1g5ljm5\n"
     ]
    }
   ],
   "source": [
    "# sweep_config = {\n",
    "#     'program': 'train.py',\n",
    "#     'method': 'random',  # Can be 'grid', 'random', or 'bayes'\n",
    "#     'metric': {\n",
    "#         'name': 'val_loss',  # The metric to optimize\n",
    "#         'goal': 'minimize'  # The optimization goal of the metric\n",
    "#     },\n",
    "#     'parameters': {\n",
    "#         'lr': {\n",
    "#             'distribution': 'uniform',\n",
    "#             'min': 1e-6,\n",
    "#             'max': 1e-2\n",
    "#         },\n",
    "#         'num_epochs': {\n",
    "#             'values': [10, 20, 30]\n",
    "#         },\n",
    "#         'batch_size': {\n",
    "#             'values': [16, 32, 64]\n",
    "#         },\n",
    "#         'optimizer': {\n",
    "#             'values': ['adam', 'sgd', 'adamw']\n",
    "#         },\n",
    "#         # You can add more hyperparameters as needed.\n",
    "#     }\n",
    "# }\n",
    "\n",
    "import wandb\n",
    "from utils.helper import load_config\n",
    "config_path = \"../config/sweep_model.yaml\"\n",
    "\n",
    "PROJECT = 'hutech_mushroom'\n",
    "with open(config_path, 'r') as f:\n",
    "    sweep_config = load_config(config_path)\n",
    "print(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=PROJECT)\n",
    "print(f\"Sweep ID: {sweep_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 ways to activate agent for sweeping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep ID: v1g5ljm5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ceojbpkk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontrast: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: hutech-dataset:latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tes_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thorizontal_flip: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: alexnet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_classes: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_rotation: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tresize: 224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsaturation: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: reduce_lr_on_plateau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvertical_flip: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args Namespace(model='alexnet', config=None, project='hutech_mushroom', dataset='hutech-dataset:latest')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: beehappy2554 (beehappy2554-bosch-global) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Ignoring project 'hutech_mushroom' when running a sweep.\n",
      "wandb: Tracking run with wandb version 0.19.8\n",
      "wandb: Run data is saved locally in /mnt/c/Users/beeha/VSCode/! - Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/wandb/run-20250329_173013-ceojbpkk\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run cool-sweep-1\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/beehappy2554-bosch-global/hutech_mushroom\n",
      "wandb: üßπ View sweep at https://wandb.ai/beehappy2554-bosch-global/hutech_mushroom/sweeps/v1g5ljm5\n",
      "wandb: üöÄ View run at https://wandb.ai/beehappy2554-bosch-global/hutech_mushroom/runs/ceojbpkk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here config!!! None\n",
      "HERE config! {'batch_size': 4, 'contrast': 0.2, 'dataset': 'hutech-dataset:latest', 'es_patience': 10, 'horizontal_flip': 0.5, 'lr': 1e-05, 'model': 'alexnet', 'momentum': 0.9, 'num_classes': 4, 'num_epochs': 30, 'optimizer': 'adam', 'random_rotation': 90, 'resize': 224, 'saturation': 0.2, 'scheduler': 'reduce_lr_on_plateau', 'vertical_flip': 0.5, 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1205 of 1205 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4, 'contrast': 0.2, 'dataset': 'hutech-dataset:latest', 'es_patience': 10, 'horizontal_flip': 0.5, 'lr': 1e-05, 'model': 'alexnet', 'momentum': 0.9, 'num_classes': 4, 'num_epochs': 30, 'optimizer': 'adam', 'random_rotation': 90, 'resize': 224, 'saturation': 0.2, 'scheduler': 'reduce_lr_on_plateau', 'vertical_flip': 0.5, 'weight_decay': 0.0001}\n",
      "Training model...\n",
      "Device: cuda\n",
      "Number of epochs: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fb2e34b4d60>\n",
      "Total parameters: 57020228\n",
      "Batch size: 4\n",
      "Early stopping: 10\n",
      "Dataset: 720 training samples, 120 validation samples\n",
      "Model will be saved at ../models/best-alexnet-2025-03-29-17:30:24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 144.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 1 with val loss 0.9400\n",
      "[Epoch 1/30] Train Loss: 1.1690 Val Loss: 0.9400 Train Acc: 0.4986 Val Acc: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 16.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 154.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 2 with val loss 0.5250\n",
      "[Epoch 2/30] Train Loss: 0.6434 Val Loss: 0.5250 Train Acc: 0.7583 Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 16.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 130.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 3 with val loss 0.3350\n",
      "[Epoch 3/30] Train Loss: 0.4598 Val Loss: 0.3350 Train Acc: 0.8278 Val Acc: 0.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.29it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, -570.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 4 with val loss 0.2423\n",
      "[Epoch 4/30] Train Loss: 0.3074 Val Loss: 0.2423 Train Acc: 0.9014 Val Acc: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.94it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 121.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 5 with val loss 0.2377\n",
      "[Epoch 5/30] Train Loss: 0.2854 Val Loss: 0.2377 Train Acc: 0.8972 Val Acc: 0.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.13it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 124.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 6 with val loss 0.1816\n",
      "[Epoch 6/30] Train Loss: 0.2059 Val Loss: 0.1816 Train Acc: 0.9306 Val Acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.02it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 7 with val loss 0.1323\n",
      "[Epoch 7/30] Train Loss: 0.2092 Val Loss: 0.1323 Train Acc: 0.9236 Val Acc: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 120.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 8 with val loss 0.1283\n",
      "[Epoch 8/30] Train Loss: 0.1903 Val Loss: 0.1283 Train Acc: 0.9333 Val Acc: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 94.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 9 with val loss 0.1065\n",
      "[Epoch 9/30] Train Loss: 0.1534 Val Loss: 0.1065 Train Acc: 0.9528 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 136.15it/s]\n",
      "  1%|          | 2/180 [00:00<00:11, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/30] Train Loss: 0.1143 Val Loss: 0.1379 Train Acc: 0.9569 Val Acc: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.30it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 145.36it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/30] Train Loss: 0.1588 Val Loss: 0.1412 Train Acc: 0.9444 Val Acc: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:11<00:00, 15.61it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 134.81it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/30] Train Loss: 0.1351 Val Loss: 0.1712 Train Acc: 0.9444 Val Acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:10<00:00, 16.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 131.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 13 with val loss 0.0808\n",
      "[Epoch 13/30] Train Loss: 0.1372 Val Loss: 0.0808 Train Acc: 0.9569 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.32it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 112.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 14 with val loss 0.0750\n",
      "[Epoch 14/30] Train Loss: 0.1291 Val Loss: 0.0750 Train Acc: 0.9514 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.81it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 99.90it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/30] Train Loss: 0.1111 Val Loss: 0.0879 Train Acc: 0.9569 Val Acc: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 16 with val loss 0.0680\n",
      "[Epoch 16/30] Train Loss: 0.1152 Val Loss: 0.0680 Train Acc: 0.9500 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.39it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 108.16it/s]\n",
      "  1%|          | 2/180 [00:00<00:13, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/30] Train Loss: 0.0897 Val Loss: 0.0792 Train Acc: 0.9625 Val Acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 107.77it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/30] Train Loss: 0.1139 Val Loss: 0.0957 Train Acc: 0.9542 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.77it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 110.32it/s]\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/30] Train Loss: 0.0979 Val Loss: 0.1176 Train Acc: 0.9653 Val Acc: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:00<00:00, 121.32it/s]\n",
      "  1%|          | 2/180 [00:00<00:11, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/30] Train Loss: 0.0981 Val Loss: 0.1227 Train Acc: 0.9764 Val Acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.78it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 112.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at epoch 21 with val loss 0.0645\n",
      "[Epoch 21/30] Train Loss: 0.0898 Val Loss: 0.0645 Train Acc: 0.9694 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 114.28it/s]\n",
      "  1%|          | 2/180 [00:00<00:12, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/30] Train Loss: 0.1033 Val Loss: 0.0676 Train Acc: 0.9667 Val Acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:12<00:00, 14.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:01<00:00, 106.15it/s]\n",
      "  1%|          | 2/180 [00:00<00:12, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/30] Train Loss: 0.0713 Val Loss: 0.0645 Train Acc: 0.9708 Val Acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:13<00:00, 13.80it/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 104/120 [00:00<00:00, 127.52it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 108/120 [00:00<00:00, 121.35it/s]\n",
      "message_loop has been closed\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
      "    return self._sock_client.read_server_response(timeout=1)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 235, in read_server_response\n",
      "    data = self._read_packet_bytes(timeout=timeout)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 220, in _read_packet_bytes\n",
      "    raise SockClientClosedError\n",
      "wandb.sdk.lib.sock_client.SockClientClosedError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 56, in message_loop\n",
      "    msg = self._read_message()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
      "    raise MessageRouterClosedError from e\n",
      "wandb.sdk.interface.router.MessageRouterClosedError\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Users/beeha/VSCode/! - Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 208, in <module>\n",
      "    trainer()\n",
      "  File \"/mnt/c/Users/beeha/VSCode/! - Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 152, in trainer\n",
      "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
      "  File \"/mnt/c/Users/beeha/VSCode/! - Self-study/All HUGE Projects/Computer Vision/hutech_mushroom/src/train.py\", line 53, in validate\n",
      "    for images, labels in tqdm(loader):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 245, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 284, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/torchvision/datasets/folder.py\", line 264, in pil_loader\n",
      "    return img.convert(\"RGB\")\n",
      "KeyboardInterrupt\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "from train import trainer\n",
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "wandb.agent(sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 56, in _try_connect_to_existing_service\n",
      "    client.connect(token.port)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 102, in connect\n",
      "    s.connect((\"localhost\", port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/pytorch37/bin/wandb\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1161, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1082, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1697, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 1443, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/core.py\", line 788, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 1669, in agent\n",
      "    api = _get_cling_api()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/cli/cli.py\", line 132, in _get_cling_api\n",
      "    wandb.setup(settings=wandb.Settings(x_cli_only_mode=True))\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 382, in setup\n",
      "    return _setup(settings=settings)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 321, in _setup\n",
      "    _singleton.ensure_service()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 264, in ensure_service\n",
      "    self._connection = service_connection.connect_to_service(self._settings)\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 37, in connect_to_service\n",
      "    conn = _try_connect_to_existing_service()\n",
      "  File \"/root/anaconda3/envs/pytorch37/lib/python3.9/site-packages/wandb/sdk/lib/service_connection.py\", line 59, in _try_connect_to_existing_service\n",
      "    raise WandbServiceConnectionError(\n",
      "wandb.sdk.lib.service_connection.WandbServiceConnectionError: Failed to connect to internal service.\n"
     ]
    }
   ],
   "source": [
    "!wandb agent --count 20 {sweep_id}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
